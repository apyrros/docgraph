{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataPrep_2021-09-26.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uIw15KYmKC_a",
        "eUDKnrmNR7Qf",
        "daCfuhygCSsP",
        "GLwpc5-IUhX_",
        "KM_QnnCrX9BN",
        "qTtaqBC8Y6Ul",
        "o3ma9RURZ9e1",
        "SOwuFQnTaTTX",
        "LuaBjagvasLR",
        "G3N9psLva7HW",
        "3Hl485J0-53n",
        "iMBowQBfkrTl"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIYjj3hXIOnx"
      },
      "source": [
        "#  Data prep for the leakage problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh--Agaqa3wy"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpQfmoU_IWzt"
      },
      "source": [
        "##  Set up the correct version of SQLite3 that allows us to do `row_number()` operations\n",
        "Remember that you need to do `Menu > Runtime > restart runtime` since the runtime is already loaded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCP2XDiFH4ZA"
      },
      "source": [
        "!curl https://www.sqlite.org/src/tarball/sqlite.tar.gz?r=release | tar xz\n",
        "%cd sqlite/\n",
        "!./configure\n",
        "!make sqlite3.c\n",
        "%cd /content\n",
        "!npx degit coleifer/pysqlite3 -f\n",
        "!cp sqlite/sqlite3.[ch] .\n",
        "!python setup.py build_static build\n",
        "!cp build/lib.linux-x86_64-3.7/pysqlite3/_sqlite3.cpython-37m-x86_64-linux-gnu.so \\\n",
        "     /usr/lib/python3.7/lib-dynload/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4wIpROpJrs5"
      },
      "source": [
        "## Library imports and important settings/constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04cQLewAIyut"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from types import  SimpleNamespace\n",
        "import os.path as osp \n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab import drive \n",
        "from sqlalchemy import create_engine\n",
        "import sqlite3 as lite \n",
        "print(\"Installed SQLite version {} at least 3.25\".format(lite.sqlite_version))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEUdjTlbJy0a"
      },
      "source": [
        "YEAR = 2017  #<-- file year\n",
        "MOUNT_LOCATION = \"/content/drive/MyDrive/Docgraph\"\n",
        "\n",
        "#  Namespaces for easy access\n",
        "PUF = SimpleNamespace(zip=f\"{MOUNT_LOCATION}/Medicare_Provider_Util_Payment_PUF_CY{YEAR}.zip\", \n",
        "                      data=f\"Medicare_Provider_Util_Payment_PUF_CY{YEAR}/Medicare_Provider_Util_Payment_PUF_CY{YEAR}.txt\", \n",
        "                      dir=f\"Medicare_Provider_Util_Payment_PUF_CY{YEAR}\", \n",
        "                      table=f\"{MOUNT_LOCATION}/db/PUFF_{YEAR}.csv\", \n",
        "                      detail=f\"{MOUNT_LOCATION}/db/PUFF_DETAIL_{YEAR}.csv\")\n",
        "\n",
        "DOCGRAPH = SimpleNamespace(zip=f\"{MOUNT_LOCATION}/DocGraph_Hop_Teaming_{YEAR}_CC.zip\", \n",
        "                      data=f\"DocGraph_Hop_Teaming_{YEAR}_CC/DocGraph_Hop_Teaming_{YEAR}_CC/DocGraph_Hop_Teaming_{YEAR}.csv\", \n",
        "                      dir=f\"DocGraph_Hop_Teaming_{YEAR}_CC\", \n",
        "                      table=f\"{MOUNT_LOCATION}/db/DOCGRAPH_{YEAR}.csv\")\n",
        "\n",
        "_npi_name_lookup = {2014: f\"{YEAR}_National_Downloadable_File/National_Downloadable_File.csv\", \n",
        "                    2015: f\"{YEAR}_National_Downloadable_File/Physician_Compare_Databases/National_Downloadable_File.csv\", \n",
        "                    2016: f\"{YEAR}_National_Downloadable_File/National_Downloadable_File.csv\", \n",
        "                    2017: f\"{YEAR}_National_Downloadable_File/Physician_Compare_2014_Group_Practice_Public_Reporting_-_Clinical_Quality_Of_Care.csv\"}\n",
        "\n",
        "\n",
        " \n",
        "NPI = SimpleNamespace(zip=f\"{MOUNT_LOCATION}/{YEAR}_National_Downloadable_File.zip\", \n",
        "                      data=_npi_name_lookup[YEAR], \n",
        "                      dir=f\"{YEAR}_National_Downloadable_File\", \n",
        "                      table=f\"{MOUNT_LOCATION}/db/NPI_{YEAR}.csv\") \n",
        "\n",
        "\n",
        "#  RVU files are particularly nasty because the government has fluid naming conventions... \n",
        "_rvu_name_lookup = {2014:'RVU14A', 2015:'RVU15A', 2016:'RVU16A', 2017:'rvu17a3'}\n",
        "_rvu_file_lookup = {2014:'PPRRVU14_V1219', 2015: 'PPRRVU15_V1223c', 2016: 'PPRRVU16_V0122', 2017: 'PPRRVU17_V1219'}   \n",
        "_rvu_zip_name = _rvu_name_lookup[YEAR]\n",
        "_rvu_file_name = _rvu_file_lookup[YEAR]\n",
        "\n",
        "RVU = SimpleNamespace(zip=f\"{MOUNT_LOCATION}/{_rvu_zip_name}.zip\", \n",
        "                      data=f\"{_rvu_zip_name}/{_rvu_zip_name}/{_rvu_file_name}.csv\", \n",
        "                      dir=f\"{_rvu_zip_name}\", \n",
        "                      table=f\"{MOUNT_LOCATION}/db/RVU_{YEAR}.csv\")\n",
        "\n",
        "#  Mount the drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0anNfXPJ1Qe"
      },
      "source": [
        "#  Postgres concept on AWS\n",
        "username = \"\"\n",
        "host = \"amazonaws.com\"\n",
        "#engine = create_engine(f'postgresql://{username}:{password}@{host}:5432/dbmaster')\n",
        "\n",
        "#  Database assignment... note to self:  make sure not pointing to public Postgres anymore until ready for prime-time\n",
        "engine = create_engine(f\"sqlite:////{MOUNT_LOCATION}/data_{YEAR}.db\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIw15KYmKC_a"
      },
      "source": [
        "## Build underlying data constructs from flat files located on Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7WpdAyEKAAJ"
      },
      "source": [
        "#  \n",
        "#  Utility functions \n",
        "#\n",
        "def _get_puf_data(filename: str) -> pd.DataFrame: \n",
        "  df = pd.read_csv(filename, \n",
        "                  sep='\\t', \n",
        "                  skiprows=[1], \n",
        "                  header=0)\n",
        "  df.columns = map(str.lower, df.columns)\n",
        "  df = df.loc[df['nppes_entity_code'] == 'I'].copy() \n",
        "  cols = ['npi', 'bene_unique_cnt', 'line_srvc_cnt', 'hcpcs_code']  \n",
        "  df = df[cols].copy()\n",
        "  return df \n",
        "\n",
        "def _em_ratio(data: pd.DataFrame) -> pd.Series:\n",
        "  num = np.sum(data.office.values * data.bene_unique_cnt.values)\n",
        "  denom = np.sum(data.bene_unique_cnt.values)\n",
        "  return pd.Series(dict(em_ratio=num/denom))\n",
        "\n",
        "#\n",
        "#  PUF files -- detail and aggregated for E&M \n",
        "#\n",
        "!unzip {PUF.zip} -d {PUF.dir}\n",
        "df = _get_puf_data(filename=PUF.data)\n",
        "df.to_csv(PUF.detail, index=False)\n",
        "df['office'] = [int(x[:3] == '992') for x in df.hcpcs_code.values]  #Try to capture all the EM codes starting with 992... \n",
        "df.drop('hcpcs_code', axis=1, inplace=True)\n",
        "puf = df.groupby(['npi']).apply(_em_ratio)\n",
        "puf = puf.reset_index()\n",
        "puf.to_csv(PUF.table, index=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDlNTK5l1HEu"
      },
      "source": [
        "#\n",
        "#  NPI files\n",
        "#\n",
        "if YEAR != 2017: \n",
        "  !unzip {NPI.zip} -d {NPI.dir}\n",
        "  df = pd.read_csv(NPI.data)\n",
        "else: \n",
        "  df = pd.read_csv(\"/content/drive/MyDrive/Docgraph/2017-02-Physician_Compare_National_Downloadable_File.csv\")\n",
        "  \n",
        "df.columns = map(str.lower, df.columns)\n",
        "columns = ['npi','pac id','last name','first name', \n",
        "           'gender','graduation year','primary specialty', 'organization legal name', 'group practice pac id', \n",
        "           'number of group practice members','city','state','zip code']\n",
        "df = df[columns].copy()\n",
        "df.rename(columns={'number of group practice members': 'group_size', 'zip code': 'zipcode'}, inplace=True)\n",
        "df.to_csv(NPI.table, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixoJ7nFuMUIM"
      },
      "source": [
        "#\n",
        "#  RVU files\n",
        "#  Note:  Take heed with this... the government files aren't very consistent\n",
        "#\n",
        "!unzip {RVU.zip} -d {RVU.dir}\n",
        "df = pd.read_csv(f\"{RVU.data}\", header=0, skiprows=[0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
        "df = df[['HCPCS', 'MOD', 'RVU']].copy()\n",
        "df['modifier'] = df['MOD'].fillna(0)\n",
        "df = df.iloc[np.where((df.RVU.values > 0 ) & (df.modifier.values == 0))[0]].copy()\n",
        "df.drop(['MOD', 'modifier'], axis=1, inplace=True)\n",
        "df.to_csv(RVU.table, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8kyzescBR6S"
      },
      "source": [
        "\n",
        "#\n",
        "#  Docgraph HOPPR file\n",
        "#\n",
        "!unzip {DOCGRAPH.zip} -d {DOCGRAPH.dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TanOoUpjSwol"
      },
      "source": [
        "if YEAR == 2017: \n",
        "  docgraph = pd.read_csv(\"DocGraph_Hop_Teaming_2017_CC/DocGraph_Hop_Teaming_2017_Non_Commercial/DocGraph_Hop_Teaming_2017.csv\")\n",
        "  \n",
        "else: \n",
        "  docgraph = pd.read_csv(DOCGRAPH.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVfA2Z4IF-0h"
      },
      "source": [
        "docgraph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOI9ogseFENj"
      },
      "source": [
        "docgraph.drop(['transaction_count', 'std_day_wait'], axis=1, inplace=True)\n",
        "df_docgraph_ttl = docgraph.groupby('from_npi').agg({'patient_count': 'sum'}).rename(columns={'patient_count':'ttl_patient_count'}).reset_index()\n",
        "df = docgraph.merge(df_docgraph_ttl, on='from_npi', how='inner')\n",
        "df.to_csv(DOCGRAPH.table, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_e9t1q4KQle"
      },
      "source": [
        "## SQL dataprep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb_y9SinLJLj"
      },
      "source": [
        "### Create tables from files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mu4cTFQKedu"
      },
      "source": [
        "#### PUF, NPI and DOCGRAPH files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myXFvk6nKaJl"
      },
      "source": [
        "puf = pd.read_csv(PUF.table)\n",
        "npi = pd.read_csv(NPI.table)\n",
        "# TODO: refactor so that this is done earlier on for consistency\n",
        "npi.columns = map(lambda s: s.replace(\" \", \"_\"), npi.columns)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-iVEe17KzQz"
      },
      "source": [
        "#\n",
        "#  Create NPI and PUF tables \n",
        "#\n",
        "npi.to_sql(\"npi\", engine, if_exists=\"replace\")\n",
        "puf.to_sql('puf', engine, if_exists='replace')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0EWtc0HK2Dk"
      },
      "source": [
        "zip_centroid = pd.read_csv(f'{MOUNT_LOCATION}/us-zip-code-latitude-and-longitude.csv', delimiter=\";\")\n",
        "zip_centroid.drop(['City', 'State', 'Timezone', 'Daylight savings time flag', 'geopoint'], axis=1, inplace=True)\n",
        "zip_centroid.to_sql(\"zipcode\", engine, if_exists=\"replace\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4jUca3TLrju"
      },
      "source": [
        "docgraph = pd.read_csv(DOCGRAPH.table)\n",
        "docgraph.drop(['ttl_patient_count'], axis=1, inplace=True)  # Don't think we ever use this "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unOND2iQK4-n"
      },
      "source": [
        "#\n",
        "#  Create a docgraph table comprised of the network TO radiologist community... this is huge so takes a long time, change codes as needed: https://www.cms.gov/Medicare/Quality-Initiatives-Patient-Assessment-Instruments/Care-Compare-DAC-Initiative/Frequently-Asked-Questions\n",
        "#\n",
        "query = \"\"\"\n",
        "select distinct npi \n",
        "from npi \n",
        "where primary_specialty in \n",
        "(\n",
        "  'INTERVENTIONAL RADIOLOGY', 'DIAGNOSTIC RADIOLOGY', 'NUCLEAR MEDICINE' \n",
        ")\n",
        "\"\"\"\n",
        "docs_we_care_about = pd.read_sql_query(query, engine)\n",
        "_docgraph = docgraph.merge(docs_we_care_about, how='inner', left_on=\"to_npi\", right_on=\"npi\")\n",
        "_docgraph.to_sql(\"docgraph\", engine, if_exists=\"replace\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D25Tqyc5Eeoq"
      },
      "source": [
        "_docgraph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIsRUThpLDek"
      },
      "source": [
        "#### Radiology academic centers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kStA_18yK8T5"
      },
      "source": [
        "#\n",
        "#  Academic centers from Harvey  \n",
        "#  \n",
        "df = pd.read_csv(f'{MOUNT_LOCATION}/Radiology_AcademicPractices.csv')\n",
        "df.columns = map(lambda s: s.replace(\" \", \"_\").lower().replace(\"?\", \"_ind\"), df.columns)\n",
        "df = df.loc[df['academic_ind'] == 1].copy().reset_index()\n",
        "#df.drop(['organization_name', 'city', 'state', 'academic_ind'])\n",
        "#df.to_sql(\"academic\", engine, if_exists=\"replace\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IARNcO74fdhY"
      },
      "source": [
        "df.drop(['index', 'organization_name', 'city', 'state', 'academic_ind'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yHPPM9Uf30V"
      },
      "source": [
        "df.to_sql(\"academic\", engine, if_exists=\"replace\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qr3_b08cLY-L"
      },
      "source": [
        "#### SDI "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2ZdylWbLb2X"
      },
      "source": [
        "#\n",
        "#  SDI features\n",
        "#\n",
        "df = pd.read_csv(f'{MOUNT_LOCATION}/ACS2015_zctaallvars.csv')\n",
        "df['zipcode'] = [str(s).rjust(5, '0') for s in df.zcta.values]\n",
        "df = df[['zipcode','population','sdi_score','highneeds_score']].copy()\n",
        "df.to_sql(\"sdi\", engine, if_exists=\"replace\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5U3iOlhLhoj"
      },
      "source": [
        "#### RVU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8yBCY9jLeVn"
      },
      "source": [
        "#  \n",
        "#  RVU table \n",
        "#\n",
        "rvu = pd.read_csv(RVU.table)\n",
        "rvu.to_sql(\"rvu\", engine, if_exists=\"replace\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEqqhKL5MC8c"
      },
      "source": [
        "#### PUF detail"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTHgqBU-LXmR"
      },
      "source": [
        "#\n",
        "#  PUF detail table \n",
        "#\n",
        "puf_detail = pd.read_csv(PUF.detail)\n",
        "puf_detail.to_sql(\"puf_detail\", engine, if_exists=\"replace\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJWJvlnZA06y"
      },
      "source": [
        "### Urban_zip file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkyYzLz1AxBV"
      },
      "source": [
        "df = pd.read_csv(f'{MOUNT_LOCATION}/rural_urban.txt', delimiter='\\t')\n",
        "df['zcta'] = [str(s).rjust(5, '0') for s in df.ZCTA5.values]\n",
        "df['urban'] = df['urban_rural-percent-urban_population-of-total_population']\n",
        "urban = df[['zcta', 'urban']].copy()\n",
        "\n",
        "df = pd.read_csv(f'{MOUNT_LOCATION}/Zip_to_zcta_crosswalk_2020.csv')\n",
        "df['zcta'] = [str(s).rjust(5, '0') for s in df.ZCTA.values]\n",
        "df['zip'] = [str(s).rjust(5, '0') for s in df.ZIP_CODE.values]\n",
        "zcta_map = {a: b for a, b in zip(df.zcta.values, df.zip.values)}\n",
        "\n",
        "urban['zip'] = [zcta_map.get(zcta, '99999') for zcta in urban.zcta.values]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA34MAa6EXcE"
      },
      "source": [
        "urban.to_sql(\"zip_urban\", engine, if_exists=\"replace\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EkX4VwrMTag"
      },
      "source": [
        "### Derived tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR9VwWk5McmP"
      },
      "source": [
        "#### Create the `valid_referer` table, those that have `em_ratio > 0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJhEN7L1MIow"
      },
      "source": [
        "#\n",
        "#  Isolate only valid referring providers... \n",
        "#\n",
        "engine.execute(\"drop table if exists valid_referer\")\n",
        "query = \"\"\"\n",
        "create table valid_referer as \n",
        "select distinct npi \n",
        "from puf \n",
        "where em_ratio > 0 \n",
        "\"\"\"\n",
        "engine.execute(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRCwJ_k1MvuP"
      },
      "source": [
        "#### Get only a single pairing of npi to group practice to create `npi_x_group`\n",
        "Here we make the choice to limit it to a single group... "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXhFLUgfNbZY"
      },
      "source": [
        "#\n",
        "#   Get only a single pairing of npi to group practice... \n",
        "#  \n",
        "engine.execute(\"drop table if exists npi_x_group\")\n",
        "query = \"\"\"\n",
        "create table npi_x_group as \n",
        "select npi, group_practice_pac_id\n",
        "from \n",
        "(\n",
        "  select npi, group_practice_pac_id, group_size, \n",
        "    row_number() over (partition by npi order by group_size desc) as rn\n",
        "  from \n",
        "  (\n",
        "    select distinct npi, group_practice_pac_id, group_size\n",
        "    from npi \n",
        "  ) x\n",
        ") y \n",
        "where y.rn = 1 \n",
        "\"\"\"\n",
        "engine.execute(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fTYY-KOzZvh"
      },
      "source": [
        "#### npi_x_group_weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1waeafUznSz"
      },
      "source": [
        "engine.execute(\"drop table if exists npi_x_group_weight\")\n",
        "query = \"\"\"\n",
        "create table npi_x_group_weight as \n",
        "select z.*\n",
        "from \n",
        "(\n",
        "select x.npi, x.group_practice_pac_id,\n",
        "    sum(case when trim(pc.hcpcs_code) in ('77084', '75554', '75555', '75552', '75553', '75556', '75565', '75557', '75558', '75560', '75559', '75564', '75562', '75563', '75561', '76375', '74177', '74176', '74178', '74160', '74170', '74150', '74174', '74175', '71275', '70496', '73706', '70498', '72191', '73206', '76071', '76070', '77079', '77078', '72126', '72127', '72125', '74263', '74262', '74261', '76360', '76370', '76355', '76362', '77013', '77012', '77014', '77011', '70460', '70470', '70450', '75572', '75571', '75573', '76380', '73701', '73702', '73700', '72132', '72133', '72131', '70487', '70488', '70486', '70481', '70482', '70480', '72193', '72194', '72192', '70491', '70492', '70490', '72129', '72130', '72128', '71260', '71270', '71250', '73201', '73202', '73200', '75635', '75574', '77022', '77021', '74185', '71555', '70545', '70546', '70544', '73725', '70548', '70549', '70547', '72198', '72159', '73225', '76393', '76394', '74182', '74183', '74181', '73722', '73723', '73721', '73222', '73223', '73221', '76400', '70552', '70551', '70553', '70554', '70555', '70558', '70559', '70557', '77059', '77058', '76094', '76093', '71551', '71552', '71550', '73719', '73720', '73718', '70542', '70543', '70540', '72196', '72197', '72195', '76390', '72142', '72156', '72141', '72149', '72158', '72148', '72147', '72157', '72146', '73220', '73219', '73218', '76497', '76498') \n",
        "      then pc.bene_unique_cnt else 0 end) as rads_bene, \n",
        "    sum(pc.bene_unique_cnt) as ttl_bene\n",
        "  from npi_x_group x \n",
        "    inner join puf_detail pc \n",
        "    on x.npi = pc.npi\n",
        "  group by x.npi, x.group_practice_pac_id\n",
        ") z\n",
        "where rads_bene > 0\n",
        "\"\"\"\n",
        "engine.execute(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdHlXWan3ZwQ"
      },
      "source": [
        "#### Rad group weighting\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D3my2_a3Yfn"
      },
      "source": [
        "engine.execute(\"drop table if exists group_weight\")\n",
        "query = \"\"\"\n",
        "create table group_weight as \n",
        "select group_practice_pac_id, rads_bene, ttl_bene, \n",
        "  ((rads_bene*1.0)/ttl_bene) as group_weight\n",
        "from \n",
        "(\n",
        "  select group_practice_pac_id, \n",
        "    sum(rads_bene) as rads_bene, \n",
        "    sum(ttl_bene) as ttl_bene\n",
        "  from npi_x_group_weight\n",
        "  group by group_practice_pac_id\n",
        ") x \n",
        "\"\"\"\n",
        "engine.execute(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUDKnrmNR7Qf"
      },
      "source": [
        "#### Associate the `from_npi` (referrer) to a group, and sum up the number of patients referred"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqRDTRsTR1wN"
      },
      "source": [
        "#\n",
        "#  Intermediate step... associate the referral to a group and calculate some statistics \n",
        "#\n",
        "engine.execute(\"drop table if exists from_npi_x_to_group\")\n",
        "query = \"\"\"\n",
        "create table from_npi_x_to_group as \n",
        "select d.from_npi, n.group_practice_pac_id, \n",
        "  sum(d.patient_count) as patient_count, \n",
        "  avg(d.average_day_wait) as average_day_wait\n",
        "from docgraph d\n",
        "  inner join npi_x_group n \n",
        "  on d.to_npi = n.npi \n",
        "  inner join valid_referer v \n",
        "  on d.from_npi = v.npi\n",
        "where n.group_practice_pac_id is not null \n",
        "  and n.group_practice_pac_id <> ''\n",
        "group by d.from_npi, n.group_practice_pac_id\n",
        "\"\"\"\n",
        "engine.execute(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daCfuhygCSsP"
      },
      "source": [
        "#### Associate average wait time to to_NPI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HBJCdkaCR5u"
      },
      "source": [
        "#\n",
        "#  Intermediate step... associate the referral to a group and calculate some statistics \n",
        "#\n",
        "engine.execute(\"drop table if exists group_wait_time\")\n",
        "query = \"\"\"\n",
        "create table group_wait_time as \n",
        "select n.group_practice_pac_id, \n",
        "  avg(d.average_day_wait) as average_day_wait\n",
        "from docgraph d\n",
        "  inner join npi_x_group n \n",
        "  on d.to_npi = n.npi \n",
        "  inner join valid_referer v \n",
        "  on d.from_npi = v.npi\n",
        "where n.group_practice_pac_id is not null \n",
        "  and n.group_practice_pac_id <> ''\n",
        "group by n.group_practice_pac_id\n",
        "\"\"\"\n",
        "engine.execute(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLwpc5-IUhX_"
      },
      "source": [
        "#### `from_npi_ttl` Total up the patient counts for each `from_npi`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HakElOFTkea"
      },
      "source": [
        "#\n",
        "#  Total up the patient counts for referrers... \n",
        "#\n",
        "engine.execute(\"drop table if exists from_npi_ttl\")\n",
        "query = \"\"\"\n",
        "create table from_npi_ttl as \n",
        "select from_npi, sum(patient_count) as ttl_patient_count\n",
        "from from_npi_x_to_group \n",
        "group by from_npi \n",
        "\"\"\"\n",
        "engine.execute(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM_QnnCrX9BN"
      },
      "source": [
        "#### `from_npi_x_to_group_ttl` put the activity summries together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFDXQ4FHXOda"
      },
      "source": [
        "#\n",
        "#  Get the referral activity for each from_npi \n",
        "#\n",
        "engine.execute(\"drop table if exists from_npi_x_to_group_ttl\")\n",
        "query = \"\"\"\n",
        "create table from_npi_x_to_group_ttl as \n",
        "select x.from_npi, x.group_practice_pac_id, x.patient_count, y.ttl_patient_count, x.average_day_wait\n",
        "from from_npi_x_to_group x \n",
        "  inner join from_npi_ttl y \n",
        "  on x.from_npi = y.from_npi\n",
        "\"\"\"\n",
        "engine.execute(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTtaqBC8Y6Ul"
      },
      "source": [
        "#### `to_group_feature` some features about the groups "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frXRaR1fYYId"
      },
      "source": [
        "engine.execute(\"drop table if exists to_npi_temp\")\n",
        "query = \"\"\"\n",
        "create table to_npi_temp as \n",
        "select distinct to_npi as npi \n",
        "from docgraph\n",
        "\"\"\"\n",
        "engine.execute(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PISo54hwZB06"
      },
      "source": [
        "engine.execute(\"drop table if exists to_npi_detail\")\n",
        "query = f\"\"\"\n",
        "create table to_npi_detail as \n",
        "select n.npi, n.group_practice_pac_id, \n",
        "  max(case when gender = 'M' then 1 else 0 end) as ind_male, \n",
        "  avg({YEAR} - graduation_year) as yrs_graduation\n",
        "from to_npi_temp x \n",
        "  inner join npi n \n",
        "  on x.npi = n.npi\n",
        "group by n.npi, n.group_practice_pac_id \t\n",
        "\"\"\"\n",
        "engine.execute(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCVy9mRHZD2C"
      },
      "source": [
        "engine.execute(\"drop table if exists to_group_feature\")\n",
        "query = f\"\"\"\n",
        "create table to_group_feature as \n",
        "select group_practice_pac_id, count(distinct npi) as n_radiologists, avg(ind_male) as avg_male, avg(yrs_graduation) as avg_yrs_graduation\n",
        "from to_npi_detail\n",
        "group by group_practice_pac_id\n",
        "\"\"\"\n",
        "engine.execute(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3ma9RURZ9e1"
      },
      "source": [
        "####  `referral_feature` for features about each referrer (`from_npi`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10v-eK4yZKis"
      },
      "source": [
        "#\n",
        "#  Features for the referring NPI... making sure only 1 per npi\n",
        "#\n",
        "engine.execute(\"drop table if exists referral_feature\")\n",
        "query = f\"\"\"\n",
        "create table referral_feature as  \n",
        "select npi, zipcode, ind_male, group_size, primary_specialty, yrs_graduation\n",
        "from \n",
        "(\n",
        "select n.*, \n",
        "    row_number() over (partition by n.npi order by group_size desc, zipcode) as rn \n",
        "  from \n",
        "  (\n",
        "    select npi, \n",
        "      substr('00000' || substr(cast(zipcode as text), 1, 5), -5, 5) as zipcode, \n",
        "      case when gender = 'M' then 1 else 0 end as ind_male, \n",
        "      group_size, \n",
        "      primary_specialty, \n",
        "      ({YEAR} - graduation_year) as yrs_graduation\n",
        "    from npi\n",
        "  ) as n \n",
        ") n1 \n",
        "where n1.rn = 1\n",
        "\"\"\"\n",
        "engine.execute(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOwuFQnTaTTX"
      },
      "source": [
        "####  `npi_rvu` estimate the RVU for each provider "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yrAHJN_aLnF"
      },
      "source": [
        "#\n",
        "#  Create an estimate of RVU for each npi \n",
        "#\n",
        "engine.execute(\"drop table if exists npi_rvu\")\n",
        "query = \"\"\"\n",
        "create table npi_rvu as \n",
        "select p.npi, sum(coalesce(r.rvu, 0.0) * p.line_srvc_cnt) as rvu \n",
        "from puf_detail p \n",
        "  left join rvu r \n",
        "  on p.hcpcs_code = r.hcpcs \n",
        "group by p.npi \n",
        "\"\"\"\n",
        "engine.execute(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuaBjagvasLR"
      },
      "source": [
        "#### `group_rvu` to estimate the RVU for each of our groups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkw78b4wagHo"
      },
      "source": [
        "#\n",
        "#  Estimate RVU for our to_groups\n",
        "# \n",
        "engine.execute(\"drop table if exists group_rvu\")\n",
        "query = \"\"\"\n",
        "create table group_rvu as \n",
        "select x.group_practice_pac_id, sum(rvu) as rvu \n",
        "from npi_x_group x \n",
        "  inner join npi_rvu r \n",
        "  on x.npi = r.npi \n",
        "group by x.group_practice_pac_id\n",
        "\"\"\"\n",
        "engine.execute(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3N9psLva7HW"
      },
      "source": [
        "#### `group_zip` to associate a single zip to a group. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKkQspOAa2gC"
      },
      "source": [
        "#\n",
        "#  Group zip centroid\n",
        "#\n",
        "engine.execute(\"drop table if exists group_zip\")\n",
        "query = \"\"\"\n",
        "create table group_zip as \n",
        "select group_practice_pac_id, zipcode \n",
        "from \n",
        "(\n",
        "  select a.*, \n",
        "    row_number() over (partition by group_practice_pac_id order by group_size desc, zipcode) as rn \n",
        "  from \n",
        "  (\n",
        "    select distinct group_practice_pac_id, group_size, \n",
        "      substr('00000' || substr(cast(zipcode as text), 1, 5), -5, 5) as zipcode\n",
        "    from to_npi_temp x \n",
        "      inner join npi n \n",
        "      on x.npi = n.npi\n",
        "  ) a \n",
        ") b \n",
        "where b.rn = 1 \n",
        "\"\"\"\n",
        "engine.execute(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hl485J0-53n"
      },
      "source": [
        "#### `group_leakage` to associate leakage to a group "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFCI2IMc-43b"
      },
      "source": [
        "engine.execute(\"drop table if exists group_leakage\")\n",
        "query = \"\"\"\n",
        "create table group_leakage as \n",
        "select\n",
        "  x.group_practice_pac_id, \n",
        "  sum(x.patient_count*1.0000) as n_referral, \n",
        "  sum(x.ttl_patient_count*1.0000) as n_potential_referral,  \n",
        "  sum(x.patient_count*1.0000)/sum(x.ttl_patient_count*1.0000) as leakage\n",
        "from from_npi_x_to_group_ttl x \n",
        "where x.group_practice_pac_id is not null \n",
        "and length(x.group_practice_pac_id) > 3 \n",
        "and x.ttl_patient_count > 0\n",
        "and x.patient_count > 0 \n",
        "group by x.group_practice_pac_id\n",
        "\"\"\"\n",
        "engine.execute(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMVN5zQya5pd"
      },
      "source": [
        "#  Feature space "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEb4KMN8bSY0"
      },
      "source": [
        "query = \"\"\"\n",
        "select\n",
        "  (x.patient_count*1.0000)/(x.ttl_patient_count*1.0000) as leakage, \n",
        "  x.from_npi, \n",
        "  nxg.group_practice_pac_id as from_group_practice_pac_id, \n",
        "  x.group_practice_pac_id as to_group_practice_pac_id, \n",
        "  rf.zipcode,\n",
        "  x.patient_count, x.ttl_patient_count,\n",
        "  rf.ind_male, rf.group_size, rf.primary_specialty, rf.yrs_graduation, \n",
        "  f.n_radiologists, x.average_day_wait, \n",
        "  coalesce(z.latitude, 0) as latitude, \n",
        "  coalesce(z.longitude, 0) as longitude, \n",
        "  coalesce(g.rvu, 0)/f.n_radiologists as normalized_rvu, \n",
        "  coalesce(zz.latitude, 0) as to_latitude, \n",
        "  coalesce(zz.longitude, 0) as to_longitude, \n",
        "  s.population,s.sdi_score,s.highneeds_score, \n",
        "  case when ac.group_id is not null then 1 else 0 end as ind_academic, \n",
        "  case when nxg.group_practice_pac_id = x.group_practice_pac_id then 1 else 0 end as ind_internal_referral\n",
        "from from_npi_x_to_group_ttl x \n",
        "  inner join to_group_feature f \n",
        "  on x.group_practice_pac_id = f.group_practice_pac_id\n",
        "  inner join referral_feature rf \n",
        "  on x.from_npi = rf.npi \n",
        "  left join zipcode z \n",
        "  on rf.zipcode = z.zip \n",
        "  left join group_rvu g\n",
        "  on x.group_practice_pac_id = g.group_practice_pac_id\n",
        "  inner join group_zip gz \n",
        "  on x.group_practice_pac_id = gz.group_practice_pac_id\n",
        "  left join zipcode zz\n",
        "  on gz.zipcode = zz.zip \n",
        "  inner join sdi s \n",
        "  on rf.zipcode = s.zipcode\n",
        "  inner join npi_x_group nxg \n",
        "  on x.from_npi = nxg.npi\n",
        "  left join \n",
        "  (\n",
        "    select distinct group_id \n",
        "    from academic \n",
        "  ) ac on x.group_practice_pac_id = ac.group_id\n",
        "where f.n_radiologists > 1 \n",
        "and x.group_practice_pac_id is not null \n",
        "and length(x.group_practice_pac_id) > 3 \n",
        "and x.ttl_patient_count > 0\n",
        "and g.rvu > 0 \n",
        "and x.patient_count > 0 \n",
        "\"\"\"\n",
        "df = pd.read_sql_query(query, engine)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMBowQBfkrTl"
      },
      "source": [
        "## Geo distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pINbJHTekpuF"
      },
      "source": [
        "from geopy import distance\n",
        "d = df[['latitude', 'longitude', 'to_latitude', 'to_longitude']].copy()\n",
        "d['distance'] = d.apply(lambda x: distance.distance((x['latitude'], x['longitude']), (x['to_latitude'], x['to_longitude'])).km, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6MOD4c6kEX-"
      },
      "source": [
        "df['distance'] = d.distance.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HziX8Qr9mai_"
      },
      "source": [
        "df.dropna(axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAKA31emotW1"
      },
      "source": [
        "df.to_csv(f'{MOUNT_LOCATION}/db/X_{YEAR}.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jtfGoWoo9JH"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYvnH5BW9U-F"
      },
      "source": [
        "## Prepare it at the radiologist group level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edDyNzcO9UVK"
      },
      "source": [
        "query = \"\"\"\n",
        "select\n",
        "  x.group_practice_pac_id, x.n_referral, x.n_potential_referral, x.leakage, \n",
        "  f.n_radiologists, \n",
        "   coalesce(g.rvu, 0)/f.n_radiologists as normalized_rvu, \n",
        "  coalesce(zz.latitude, 0) as to_latitude, \n",
        "  coalesce(zz.longitude, 0) as to_longitude, \n",
        "  case when ac.group_id is not null then 1 else 0 end as ind_academic, \n",
        "  gwt.average_day_wait, \n",
        "  coalesce(zu.urban, 0) as pct_urban,\n",
        "\n",
        "  coalesce(s.population, 0) as population,\n",
        "  coalesce(s.sdi_score,0) as sdi_score,\n",
        "  coalesce(s.highneeds_score, 0) as highneeds_score, \n",
        "\n",
        "  gw.rads_bene, gw.ttl_bene, \n",
        "  gw.rads_bene, ttl_bene, \n",
        "  ((rads_bene*1.0)/ttl_bene) as group_weight\n",
        "\n",
        "from group_leakage x\n",
        "  inner join to_group_feature f \n",
        "  on x.group_practice_pac_id = f.group_practice_pac_id\n",
        "  left join group_rvu g\n",
        "  on x.group_practice_pac_id = g.group_practice_pac_id\n",
        "  inner join group_zip gz \n",
        "  on x.group_practice_pac_id = gz.group_practice_pac_id\n",
        "  left join zipcode zz\n",
        "  on gz.zipcode = zz.zip \n",
        "  left join \n",
        "  (\n",
        "    select distinct group_id \n",
        "    from academic \n",
        "  ) ac on x.group_practice_pac_id = ac.group_id\n",
        "  inner join group_wait_time gwt\n",
        "  on x.group_practice_pac_id = gwt.group_practice_pac_id \n",
        "  inner join zip_urban zu \n",
        "  on gz.zipcode = zu.zip\n",
        "\n",
        "  inner join sdi s \n",
        "  on gz.zipcode = s.zipcode\n",
        "\n",
        "  inner join group_weight gw\n",
        "  on x.group_practice_pac_id = gw.group_practice_pac_id\n",
        "\n",
        "\n",
        "where gwt.average_day_wait > 0 \n",
        "\"\"\"\n",
        "df = pd.read_sql_query(query, engine)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dRrX41_6wm_"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm3_LZtdQVF4"
      },
      "source": [
        "np.average(1-df.leakage.values, weights=df.group_weight.values), np.average(1-df.leakage.values), np.mean((1.-df.leakage.values)*df.group_weight.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg0GobXQACNd"
      },
      "source": [
        "df['weighted_leakage'] = (1. - df.leakage.values) * df.group_weight.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxafrrHwH6pC"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-0QM-7sOVoU"
      },
      "source": [
        "plt.hist(df.weighted_leakage.values), df.weighted_leakage.values.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_ioNNQC-LBW"
      },
      "source": [
        "df.dropna(axis=0, inplace=True)\n",
        "df.to_csv(f'{MOUNT_LOCATION}/db/X_group_{YEAR}_weight.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX7TbnNd-wGF"
      },
      "source": [
        "plt.hist(df.leakage, bins=100, density=True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaYV1PQLDjWA"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.kdeplot(df.leakage, df.n_radiologists)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnuWWxgnDpe4"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83p0SdAADwlE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nboKspO7p2Md"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis of top CPT codes"
      ],
      "metadata": {
        "id": "8fbUTxcy-hqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "select * from docgraph\n",
        "\"\"\"\n",
        "#   where trim(pc.hcpcs_code) in ('77084', '75554', '75555', '75552', '75553', '75556', '75565', '75557', '75558', '75560', '75559', '75564', '75562', '75563', '75561', '76375', '74177', '74176', '74178', '74160', '74170', '74150', '74174', '74175', '71275', '70496', '73706', '70498', '72191', '73206', '76071', '76070', '77079', '77078', '72126', '72127', '72125', '74263', '74262', '74261', '76360', '76370', '76355', '76362', '77013', '77012', '77014', '77011', '70460', '70470', '70450', '75572', '75571', '75573', '76380', '73701', '73702', '73700', '72132', '72133', '72131', '70487', '70488', '70486', '70481', '70482', '70480', '72193', '72194', '72192', '70491', '70492', '70490', '72129', '72130', '72128', '71260', '71270', '71250', '73201', '73202', '73200', '75635', '75574', '77022', '77021', '74185', '71555', '70545', '70546', '70544', '73725', '70548', '70549', '70547', '72198', '72159', '73225', '76393', '76394', '74182', '74183', '74181', '73722', '73723', '73721', '73222', '73223', '73221', '76400', '70552', '70551', '70553', '70554', '70555', '70558', '70559', '70557', '77059', '77058', '76094', '76093', '71551', '71552', '71550', '73719', '73720', '73718', '70542', '70543', '70540', '72196', '72197', '72195', '76390', '72142', '72156', '72141', '72149', '72158', '72148', '72147', '72157', '72146', '73220', '73219', '73218', '76497', '76498') \n",
        "#select pc.hcpcs_code, sum(pc.bene_unique_cnt) as sum_bene_unique_cnt\n",
        "#  from docgraph x \n",
        "#    inner join puf_detail pc \n",
        "#    on x.to_npi = pc.npi\n",
        "#  group by pc.hcpcs_code]\n",
        "\n",
        "#select pc.hcpcs_code, sum(pc.bene_unique_cnt) as sum_bene_unique_cnt\n",
        "#  from puf_detail pc\n",
        "#    inner join (select distinct to_npi from docgraph) x \n",
        "#    on x.to_npi = pc.npi\n",
        "#  group by pc.hcpcs_code\n",
        "\n",
        "df = pd.read_sql_query(query, engine)"
      ],
      "metadata": {
        "id": "Wieqxote-mUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"SELECT name FROM sqlite_master WHERE type='table';\n",
        "\"\"\"\n",
        "\n",
        "df = pd.read_sql_query(query, engine)\n",
        "df\n"
      ],
      "metadata": {
        "id": "PSopknKMpQrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"SELECT * FROM docgraph\n",
        "\"\"\"\n",
        "\n",
        "df = pd.read_sql_query(query, engine)\n",
        "df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IFEZ8mdUqPOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(f'{MOUNT_LOCATION}/db/group_zip_{YEAR}.csv', index=False)"
      ],
      "metadata": {
        "id": "YzlMJod0zFfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort_values('sum_bene_unique_cnt', ascending=False, inplace=True)"
      ],
      "metadata": {
        "id": "nlZvYB3j_TQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.iloc[:50].copy()\n",
        "df"
      ],
      "metadata": {
        "id": "hNt8hUwr_0Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "df.to_csv (\"docgraph2017_rad_dataframe.csv\", index = False, header=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lbn2JfUOALmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/My Drive/docgraph2017_rad_dataframe.csv'\n",
        "\n",
        "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
        "  df.to_csv(f)"
      ],
      "metadata": {
        "id": "yYC8aK2h7KpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhZOCnldpdVR"
      },
      "source": [
        "X = df[['leakage', 'n_radiologists', 'average_day_wait', 'normalized_rvu', 'distance', 'ind_academic']].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNRJ4jaRqMVd"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehTp8mgLqNMe"
      },
      "source": [
        "X = X.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfiK8IenqYtk"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqIwZPIuqZJJ"
      },
      "source": [
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGm7NwA2qbuC"
      },
      "source": [
        "sns.set_theme(style=\"ticks\")\n",
        "\n",
        "sns.pairplot(X, hue=\"ind_academic\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3T8A9xhqwRD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}